"Jennifer Schrack",
"Karen Bandeen-Roche",
"Mara McAdams DeMarco",
"Michelle Carlson",
"Qian-Li Xue",
"Ravi Varadhan",
"Rickey Sharrett",
"Sevil Yasar",
"Keri Althoff",
"Glenn Ostir",
"Michael Terrin",
"Elizabeth Colantuoni")
judges <- sort(judges)
presenters <- c("Brian Buta",
"Chi Chiung Grace Chen",
"Marian Tzuang",
"Jiawei Bai",
"Yuanting Zha",
"Alexandra Lee",
"Anthony Nastasi",
"Laura Bozzi",
"Andrea Yonge",
"Junrui Di",
"Ryan Andrews",
"Danielle Abraham",
"Michelle Sun",
"Jingwen Tan",
"Loretta Anderson",
"Ilynn Bulatao",
"Sarah Rasmussen",
"Bridget Burke",
"Brian Chen",
"Nancy Chiles Shaffer",
"Alexandra Mihailovic",
"Anna McCarrey",
"Jacek Urbanek",
"Qu Tian",
"Tabassum Majid")
n.j <- length(judges)
n.p <- length(presenters)
(n.p + 1)*3/n.j
rm(list=ls())
judges <- c("Alden Gross",
"Eleanor Simonsick",
"George Rebok",
"Jay Magaziner",
"Jennifer Schrack",
"Karen Bandeen-Roche",
"Mara McAdams DeMarco",
"Michelle Carlson",
"Qian-Li Xue",
"Ravi Varadhan",
"Rickey Sharrett",
"Sevil Yasar",
"Keri Althoff",
"Glenn Ostir",
"Michael Terrin",
"Elizabeth Colantuoni")
judges <- sort(judges)
presenters <- c("Brian Buta",
"Chi Chiung Grace Chen",
"Marian Tzuang",
"Jiawei Bai",
"Yuanting Zha",
"Alexandra Lee",
"Anthony Nastasi",
"Laura Bozzi",
"Andrea Yonge",
"Junrui Di",
"Ryan Andrews",
"Danielle Abraham",
"Michelle Sun",
"Jingwen Tan",
"Loretta Anderson",
"Ilynn Bulatao",
"Sarah Rasmussen",
"Bridget Burke",
"Brian Chen",
"Nancy Chiles Shaffer",
"Alexandra Mihailovic",
"Anna McCarrey",
"Jacek Urbanek",
"Qu Tian",
"Tabassum Majid")
n.j <- length(judges)
n.p <- length(presenters)
n.p * 3/n.j
##Generate a data frame called match with the presenters, for each of whom
##we will match 3 judges
match <- data.frame(presenters)
##Time constraints from judges
##Liz Colantuoni can stay from 1:30-3
##We will fix that she gets 3 presenters
lizColantuoni <- which(judges == "Elizabeth Colantuoni")
judges
glenOstir <- which(judges == "Glenn Ostir")
glennOstir <- which(judges == "Glenn Ostir")
rm(glenOstir)
x <- 1:length(judges)
x <- x[-lizColantuoni]
hat <- rep(x, 5)
x <- 1:length(judges)
x <- x[-c(lizColantuoni,glennOstir)]
x
judges
hat <- rep(x, 5)
samp <- sample(hat, size = (n.p*3-3), replace = FALSE)
samp <- sample(hat, size = (n.p*3-7), replace = FALSE)
samp <- c(samp, rep(lizColantuoni,3), rep(glennOstir,4))
samp
table(samp)
match$judge1 <- NA
match$judge2 <- NA
match$judge3 <- NA
for (i in 1:n.p){
temp <- NA
while(length(unique(temp))<3){
temp <- sample(samp, size = 3, replace = FALSE)
}
match$judge1[i] <- temp[1]
match$judge2[i] <- temp[2]
match$judge3[i] <- temp[3]
r1 <- which(samp == temp[1])[1]
r2 <- which(samp == temp[2])[1]
r3 <- which(samp == temp[3])[1]
samp <- samp[-c(r1, r2, r3)]
}
match
match$judge1 <- factor(match$judge1, levels = 1:length(judges), labels = judges)
match$judge2 <- factor(match$judge2, levels = 1:length(judges), labels = judges)
match$judge3 <- factor(match$judge3, levels = 1:length(judges), labels = judges)
match
r2 <- .769
1-(1-.769)*(25-1)/(25-4)
1/(1/10)
1/(5/10)
31/52
20/37
(0.103-0.104)/.104
.104*-0.009615385
rm(list=ls())
temp <- commandArgs(TRUE)
rm(list=ls())
rm(list=ls())
library(lpSolveAPI)
library(boot)
boundsNoCov_res <- function(ordinalScale, YT, YC, maxBen, maxHarm){
nT <- length(YT) #number of treatment subjects
nC <- length(YC) #number of control subjects
if(nT == 0 | nC == 0){
#warning("WARNING: YT or YC is empty")
return(c(0,1,NA))
} else {
ordinalScale <- sort(ordinalScale, decreasing = FALSE)
L <- length(ordinalScale)
varCount <- L^2 #number of pi_{i,j}'s
#The matrix of pi_{i,j}'s is a L x L matrix with varCount pi_{i,j}'s.
scale <- nT * nC ##this can be made large to help with solving the linear program
#############################################################################
##Calculate marginal cdf's##
#############################################################################
cdf_C <- rep(0,L)
for (i in 1:L){
cdf_C[i] <- sum(YC <= ordinalScale[i])/nC
}
cdf_T <- rep(0,L)
for (i in 1:L){
cdf_T[i] <- sum(YT <= ordinalScale[i])/nT
}
#############################################################################
##Which pi_{i,j}'s are affected by the restrictions?##
#############################################################################
restrictions <- matrix(0,nrow=L,ncol=L)
for (i in 1:L){
for (j in 1:L){
if (ordinalScale[j]-ordinalScale[i]>maxBen | ordinalScale[i]-ordinalScale[j]>maxHarm){
restrictions[i,j] <- 1
}
}
}
restrictions <- c(restrictions)
#############################################################################
##LP for epsilon##
#############################################################################
lprec <- make.lp(0,(varCount+1))
##Setting objective function
objfn <- c(rep(0,varCount),1)
set.objfn(lprec,objfn)
##Setting non-negativity bounds
set.bounds(lprec, lower = rep(0, (varCount+1)), upper = NULL)
##pi_{i,j}'s sum to 1
add.constraint(lprec, xt = c(rep(1,varCount),0), "=", rhs = scale)
##incorporating the restrictions
add.constraint(lprec, xt = c(restrictions,0), "=", rhs = 0)
##marginal cdf constraints
pij.matrix <- matrix(1:varCount, nrow = L, ncol = L)
for (i in 1:(L-1)){
add.constraint(lprec, xt = c(rep(1,L*i),-1), "<=", rhs = (cdf_C[i]*scale), indices = c(pij.matrix[1:i,],(varCount+1)))
add.constraint(lprec, xt = rep(1,L*i+1), ">=", rhs = (cdf_C[i]*scale), indices = c(pij.matrix[1:i,],(varCount+1)))
}
for (i in 1:(L-1)){
add.constraint(lprec, xt = c(rep(1,L*i),-1), "<=", rhs = (cdf_T[i]*scale), indices = c(pij.matrix[,1:i],(varCount+1)))
add.constraint(lprec, xt = rep(1,L*i+1), ">=", rhs = (cdf_T[i]*scale), indices = c(pij.matrix[,1:i],(varCount+1)))
}
##Solving linear program
eps.flag <- solve(lprec)
if(eps.flag != 0){
stop("WARNING: problem with LP for eps")
}
eps <- get.objective(lprec)/scale
if (eps < 10 ^ (-10)){
eps <- 0
}
rm(lprec)
#############################################################################
##LP for lb and ub##
#############################################################################
lprec <- make.lp(0,varCount)
##Setting objective function
objfn <- matrix(0, L, L)
for (i in 1:L){
for (j in 1:L){
if (ordinalScale[j]>ordinalScale[i]){
objfn[i,j] <- 1
}
}
}
objfn <- c(objfn)
set.objfn(lprec,objfn)
##Setting non-negativity bounds
set.bounds(lprec, lower = rep(0, varCount), upper = NULL)
##pi_{i,j}'s sum to 1
add.constraint(lprec, xt = rep(1,varCount), "=", rhs = scale)
##incorporating the restrictions
add.constraint(lprec, xt = restrictions, "=", rhs = 0)
##marginal cdf constraints
for (i in 1:(L-1)){
add.constraint(lprec, xt = rep(1,L*i), "<=", rhs = (cdf_C[i]+eps)*scale, indices = c(pij.matrix[1:i,]))
add.constraint(lprec, xt = rep(1,L*i), ">=", rhs = (cdf_C[i]-eps)*scale, indices = c(pij.matrix[1:i,]))
}
for (i in 1:(L-1)){
add.constraint(lprec, xt = rep(1,L*i), "<=", rhs = (cdf_T[i]+eps)*scale, indices = c(pij.matrix[,1:i]))
add.constraint(lprec, xt = rep(1,L*i), ">=", rhs = (cdf_T[i]-eps)*scale, indices = c(pij.matrix[,1:i]))
}
lb.flag <- solve(lprec)
if(lb.flag != 0){
stop("WARNING: problem with LP for lb")
}
lb <- get.objective(lprec)/scale
lp.control(lprec,sense='max')
ub.flag <- solve(lprec)
if(ub.flag != 0){
stop("WARNING: problem with LP for ub")
}
ub <- get.objective(lprec)/scale
return(c(lb,ub,eps))
}
}
compute_estimators_on_bootstrap_replicate_of_dataset <- function(data,index,ordinalScale,maxBen,maxHarm,subsampleSize){
replicate_data_set <- data[sample(1:nrow(data),size=subsampleSize,replace=TRUE),]
bounds1 <- boundsNoCov_res(ordinalScale, replicate$Y[replicate$X == 1 & replicate$A == "Surgical"], replicate$Y[replicate$X == 1 & replicate$A == "Medical"], maxBen, maxHarm)
bounds2 <- boundsNoCov_res(ordinalScale, replicate$Y[replicate$X == 2 & replicate$A == "Surgical"], replicate$Y[replicate$X == 2 & replicate$A == "Medical"], maxBen, maxHarm)
bounds <- mean(replicate$X == 1) * bounds1 + mean(replicate$X == 2) * bounds2
return(bounds)
}
setwd("~/Dropbox/research/github/fraction-who-benefit/simulationStudies/mRS180_BV/boundParameters")
load("subpop2.Rdata")
##Convert cdf's to pmf's, since that's easier to use when sampling
pT2.1 <- FT2.1 - c(0,FT2.1[-length(FT2.1)])
pT2.2 <- FT2.2 - c(0,FT2.2[-length(FT2.2)])
pC2.1 <- FC2.1 - c(0,FC2.1[-length(FC2.1)])
pC2.2 <- FC2.2 - c(0,FC2.2[-length(FC2.2)])
#############################################################################
##Simulate randomized trial and get m-out-of-n confidence interval##
#############################################################################
maxBen <- 100
maxHarm <- 100
ordinalScale <- 1:7
nsim <- 10000
set.seed(2736978)
seed <- sample(10^7,nsim)
N <- 100 ##trial size
K <- 2 ##number of strata
##Simulated the trial
data <- data.frame(A = c(rep("Medical",N/2), rep("Surgical", N/2)), Y = NA)
data$X <- sample(1:K, size = nrow(data), replace = TRUE, prob = p2)
data$Y[data$A == "Medical" & data$X == 1] <- sample(ordinalScale, size = sum(data$A == "Medical" & data$X == 1), replace = TRUE, prob = pC2.1)
data$Y[data$A == "Medical" & data$X == 2] <- sample(ordinalScale, size = sum(data$A == "Medical" & data$X == 2), replace = TRUE, prob = pC2.2)
data$Y[data$A == "Surgical" & data$X == 1] <- sample(ordinalScale, size = sum(data$A == "Surgical" & data$X == 1), replace = TRUE, prob = pT2.1)
data$Y[data$A == "Surgical" & data$X == 2] <- sample(ordinalScale, size = sum(data$A == "Surgical" & data$X == 2), replace = TRUE, prob = pT2.2)
head(data)
bootrep1 <- 5000
bootrep2 <- 10000
q <- 0.95
k <- 500
m.candidates <- unique(ceiling(N * q^(0:k)))
m.candidates
m.candidates <- m.candidates[m.candidates>=20]
m.candidates
numCandidates <- length(m.candidates)
numCandidates
temp <- table(data$A, data$X)
temp
matLB <- matrix(NA, nrow = numCandidates, ncol = bootrep1)
matUB <- matrix(NA, nrow = numCandidates, ncol = bootrep1)
bootrep1 <- 50
bootrep2 <- 100
matLB <- matrix(NA, nrow = numCandidates, ncol = bootrep1)
matUB <- matrix(NA, nrow = numCandidates, ncol = bootrep1)
for (l in 1:numCandidates){
boot.obj <- boot(data = data, statistic= compute_estimators_on_bootstrap_replicate_of_dataset, R=bootrep, ordinalScale = ordinalScale, maxBen = maxBen, maxHarm = maxHarm, subsampleSize = m.candidates[l])
matLB[l,] <- t(sort(boot.obj$t[,1], na.last = TRUE))
matUB[l,] <- t(sort(boot.obj$t[,2], na.last = TRUE))
}
for (l in 1:numCandidates){
boot.obj <- boot(data = data, statistic= compute_estimators_on_bootstrap_replicate_of_dataset, R=bootrep1, ordinalScale = ordinalScale, maxBen = maxBen, maxHarm = maxHarm, subsampleSize = m.candidates[l])
matLB[l,] <- t(sort(boot.obj$t[,1], na.last = TRUE))
matUB[l,] <- t(sort(boot.obj$t[,2], na.last = TRUE))
}
head(matLB)
bootrep1 <- 5000
bootrep2 <- 10000
q <- 0.95
k <- 500
m.candidates <- unique(ceiling(N * q^(0:k)))
m.candidates <- m.candidates[m.candidates>=50]
numCandidates <- length(m.candidates)
m.candidates
rm(list=ls())
##Convert cdf's to pmf's, since that's easier to use when sampling
pT4.1 <- FT4.1 - c(0,FT4.1[-length(FT4.1)])
setwd("~/Dropbox/research/github/fraction-who-benefit/simulationStudies/mRS180_BV/boundParameters")
load("subpop4.Rdata")
##Convert cdf's to pmf's, since that's easier to use when sampling
pT4.1 <- FT4.1 - c(0,FT4.1[-length(FT4.1)])
rm(list=ls())
rm(list=ls())
library(lpSolveAPI)
library(boot)
#############################################################################
##Function for estimating bounds##
#############################################################################
boundsNoCov_res <- function(ordinalScale, YT, YC, maxBen, maxHarm){
nT <- length(YT) #number of treatment subjects
nC <- length(YC) #number of control subjects
if(nT == 0 | nC == 0){
#warning("WARNING: YT or YC is empty")
return(c(0,1,NA))
} else {
ordinalScale <- sort(ordinalScale, decreasing = FALSE)
L <- length(ordinalScale)
varCount <- L^2 #number of pi_{i,j}'s
#The matrix of pi_{i,j}'s is a L x L matrix with varCount pi_{i,j}'s.
scale <- nT * nC ##this can be made large to help with solving the linear program
#############################################################################
##Calculate marginal cdf's##
#############################################################################
cdf_C <- rep(0,L)
for (i in 1:L){
cdf_C[i] <- sum(YC <= ordinalScale[i])/nC
}
cdf_T <- rep(0,L)
for (i in 1:L){
cdf_T[i] <- sum(YT <= ordinalScale[i])/nT
}
#############################################################################
##Which pi_{i,j}'s are affected by the restrictions?##
#############################################################################
restrictions <- matrix(0,nrow=L,ncol=L)
for (i in 1:L){
for (j in 1:L){
if (ordinalScale[j]-ordinalScale[i]>maxBen | ordinalScale[i]-ordinalScale[j]>maxHarm){
restrictions[i,j] <- 1
}
}
}
restrictions <- c(restrictions)
#############################################################################
##LP for epsilon##
#############################################################################
lprec <- make.lp(0,(varCount+1))
##Setting objective function
objfn <- c(rep(0,varCount),1)
set.objfn(lprec,objfn)
##Setting non-negativity bounds
set.bounds(lprec, lower = rep(0, (varCount+1)), upper = NULL)
##pi_{i,j}'s sum to 1
add.constraint(lprec, xt = c(rep(1,varCount),0), "=", rhs = scale)
##incorporating the restrictions
add.constraint(lprec, xt = c(restrictions,0), "=", rhs = 0)
##marginal cdf constraints
pij.matrix <- matrix(1:varCount, nrow = L, ncol = L)
for (i in 1:(L-1)){
add.constraint(lprec, xt = c(rep(1,L*i),-1), "<=", rhs = (cdf_C[i]*scale), indices = c(pij.matrix[1:i,],(varCount+1)))
add.constraint(lprec, xt = rep(1,L*i+1), ">=", rhs = (cdf_C[i]*scale), indices = c(pij.matrix[1:i,],(varCount+1)))
}
for (i in 1:(L-1)){
add.constraint(lprec, xt = c(rep(1,L*i),-1), "<=", rhs = (cdf_T[i]*scale), indices = c(pij.matrix[,1:i],(varCount+1)))
add.constraint(lprec, xt = rep(1,L*i+1), ">=", rhs = (cdf_T[i]*scale), indices = c(pij.matrix[,1:i],(varCount+1)))
}
##Solving linear program
eps.flag <- solve(lprec)
if(eps.flag != 0){
stop("WARNING: problem with LP for eps")
}
eps <- get.objective(lprec)/scale
if (eps < 10 ^ (-10)){
eps <- 0
}
rm(lprec)
#############################################################################
##LP for lb and ub##
#############################################################################
lprec <- make.lp(0,varCount)
##Setting objective function
objfn <- matrix(0, L, L)
for (i in 1:L){
for (j in 1:L){
if (ordinalScale[j]>ordinalScale[i]){
objfn[i,j] <- 1
}
}
}
objfn <- c(objfn)
set.objfn(lprec,objfn)
##Setting non-negativity bounds
set.bounds(lprec, lower = rep(0, varCount), upper = NULL)
##pi_{i,j}'s sum to 1
add.constraint(lprec, xt = rep(1,varCount), "=", rhs = scale)
##incorporating the restrictions
add.constraint(lprec, xt = restrictions, "=", rhs = 0)
##marginal cdf constraints
for (i in 1:(L-1)){
add.constraint(lprec, xt = rep(1,L*i), "<=", rhs = (cdf_C[i]+eps)*scale, indices = c(pij.matrix[1:i,]))
add.constraint(lprec, xt = rep(1,L*i), ">=", rhs = (cdf_C[i]-eps)*scale, indices = c(pij.matrix[1:i,]))
}
for (i in 1:(L-1)){
add.constraint(lprec, xt = rep(1,L*i), "<=", rhs = (cdf_T[i]+eps)*scale, indices = c(pij.matrix[,1:i]))
add.constraint(lprec, xt = rep(1,L*i), ">=", rhs = (cdf_T[i]-eps)*scale, indices = c(pij.matrix[,1:i]))
}
lb.flag <- solve(lprec)
if(lb.flag != 0){
stop("WARNING: problem with LP for lb")
}
lb <- get.objective(lprec)/scale
lp.control(lprec,sense='max')
ub.flag <- solve(lprec)
if(ub.flag != 0){
stop("WARNING: problem with LP for ub")
}
ub <- get.objective(lprec)/scale
return(c(lb,ub,eps))
}
}
setwd("~/Dropbox/research/github/fraction-who-benefit/simulationStudies/mRS180_BV/boundParameters")
load("subpop4.Rdata")
##Convert cdf's to pmf's, since that's easier to use when sampling
pT4.1 <- FT4.1 - c(0,FT4.1[-length(FT4.1)])
pT4.2 <- FT4.2 - c(0,FT4.2[-length(FT4.2)])
pT4.3 <- FT4.3 - c(0,FT4.3[-length(FT4.3)])
pT4.4 <- FT4.4 - c(0,FT4.4[-length(FT4.4)])
pC4.1 <- FC4.1 - c(0,FC4.1[-length(FC4.1)])
pC4.2 <- FC4.2 - c(0,FC4.2[-length(FC4.2)])
pC4.3 <- FC4.3 - c(0,FC4.3[-length(FC4.3)])
pC4.4 <- FC4.4 - c(0,FC4.4[-length(FC4.4)])
#############################################################################
##Simulate randomized trial and get m-out-of-n confidence interval##
#############################################################################
maxBen <- 100 ##no restrictions
maxHarm <- 100
ordinalScale <- 1:7 ##possible levels
N <- 100 ##trial size
K <- 4 ##number of strata
##These next three lines choose 10,000 seeds randomly for the 10,000 simulations
nsim <- 10000
set.seed(2736978)
seed <- sample(10^7,nsim)
data <- data.frame(A = c(rep("Medical",N/2), rep("Surgical", N/2)), Y = NA)
data$X <- sample(1:K, size = nrow(data), replace = TRUE, prob = p4)
data$Y[data$A == "Medical" & data$X == 1] <- sample(ordinalScale, size = sum(data$A == "Medical" & data$X == 1), replace = TRUE, prob = pC4.1)
data$Y[data$A == "Medical" & data$X == 2] <- sample(ordinalScale, size = sum(data$A == "Medical" & data$X == 2), replace = TRUE, prob = pC4.2)
data$Y[data$A == "Medical" & data$X == 3] <- sample(ordinalScale, size = sum(data$A == "Medical" & data$X == 3), replace = TRUE, prob = pC4.3)
data$Y[data$A == "Medical" & data$X == 4] <- sample(ordinalScale, size = sum(data$A == "Medical" & data$X == 4), replace = TRUE, prob = pC4.4)
data$Y[data$A == "Surgical" & data$X == 1] <- sample(ordinalScale, size = sum(data$A == "Surgical" & data$X == 1), replace = TRUE, prob = pT4.1)
data$Y[data$A == "Surgical" & data$X == 2] <- sample(ordinalScale, size = sum(data$A == "Surgical" & data$X == 2), replace = TRUE, prob = pT4.2)
data$Y[data$A == "Surgical" & data$X == 3] <- sample(ordinalScale, size = sum(data$A == "Surgical" & data$X == 3), replace = TRUE, prob = pT4.3)
data$Y[data$A == "Surgical" & data$X == 4] <- sample(ordinalScale, size = sum(data$A == "Surgical" & data$X == 4), replace = TRUE, prob = pT4.4)
View(data)
N <- 500
data <- data.frame(A = c(rep("Medical",N/2), rep("Surgical", N/2)), Y = NA)
data$X <- sample(1:K, size = nrow(data), replace = TRUE, prob = p4)
data$Y[data$A == "Medical" & data$X == 1] <- sample(ordinalScale, size = sum(data$A == "Medical" & data$X == 1), replace = TRUE, prob = pC4.1)
data$Y[data$A == "Medical" & data$X == 2] <- sample(ordinalScale, size = sum(data$A == "Medical" & data$X == 2), replace = TRUE, prob = pC4.2)
data$Y[data$A == "Medical" & data$X == 3] <- sample(ordinalScale, size = sum(data$A == "Medical" & data$X == 3), replace = TRUE, prob = pC4.3)
data$Y[data$A == "Medical" & data$X == 4] <- sample(ordinalScale, size = sum(data$A == "Medical" & data$X == 4), replace = TRUE, prob = pC4.4)
data$Y[data$A == "Surgical" & data$X == 1] <- sample(ordinalScale, size = sum(data$A == "Surgical" & data$X == 1), replace = TRUE, prob = pT4.1)
data$Y[data$A == "Surgical" & data$X == 2] <- sample(ordinalScale, size = sum(data$A == "Surgical" & data$X == 2), replace = TRUE, prob = pT4.2)
data$Y[data$A == "Surgical" & data$X == 3] <- sample(ordinalScale, size = sum(data$A == "Surgical" & data$X == 3), replace = TRUE, prob = pT4.3)
data$Y[data$A == "Surgical" & data$X == 4] <- sample(ordinalScale, size = sum(data$A == "Surgical" & data$X == 4), replace = TRUE, prob = pT4.4)
unique(data$Y)
table(data$Y)
rm(list=ls())
bootrep1 <- 5000
bootrep2 <- 10000
q <- 0.95
k <- 500
N <- 100
m.candidates <- unique(ceiling(N * q^(0:k)))
m.candidates
.03*2*5
10/0.03
100/.03
